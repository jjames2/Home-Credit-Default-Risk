{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e117a12-ddae-4e20-8e75-0b180e95c35b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# MATH8670 Machine Learning Competition\n",
    "\n",
    "Presenter: Jeremy James\n",
    "\n",
    "Date: 12/7/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde52a9a-1fb8-4397-9a4a-05fa7914c080",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "- Used [Sweetviz](SWEETVIZ_REPORT.html) to get a quick overview of the data\n",
    "- Dependent variable analysis\n",
    "- Differences between training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec9f24-0b6d-4de1-9950-0547370ff09f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Dependent variable analysis\n",
    "- Dependent variable is not normally distributed\n",
    "- May need to apply transformation, depending on model\n",
    "- Extremes (0 and > 1) add to confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd45e7-768b-4894-a63c-8a7fa3e2257c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Differences between training and test data\n",
    "- Train data from 2015 and prior vs test data from 2016 onwards\n",
    "- More volatile usage rates in earlier years\n",
    "- [Notebook analysis](traintestdifferences.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ed64a-9911-4900-8988-f35e61ae002a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Preparation for Design Matrix\n",
    "- XGBoost model benefited from transformed usage rate (used sklearn's QuantileTransformer)\n",
    "- Created categorical and numeric features out of date columns\n",
    "- Created Final_Allocation to Initial_Allocation ratio\n",
    "- Created previous grant count columns for organizations and Piids\n",
    "- Filtered out data prior to 2012 that are not between 0 and 1 (including 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6249f3-e9e4-4942-ba8f-715c225ba78c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Validation Approach\n",
    "- Train/test split 70/30\n",
    "- All records equally likely to be in each split\n",
    "- Review difference between MSE of model predictions and just assuming average usage rate from training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c3eb6-140a-412b-8509-41f22593ea45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Method Selection\n",
    "- Used XGBoost and InterpretML's Explainable Boosting Machine\n",
    "- Used test data, as well as Kaggle scores, to determine EBM fit the data better\n",
    "- Found XGBoost overfit the data at a typical number of boosting rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c748f-1416-4bb0-97ef-e54a60d3aa27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Parameter Tuning\n",
    "- Used test data to determine good value for min_samples_leaf for EBM\n",
    "- Applied Grid Search Cross Validation with 5 folds to find optimal parameters\n",
    "- 4 folds were used to train, 1 fold to validate\n",
    "- Searched over 3 possible values of learning_rate and 5 for min_samples_leaf\n",
    "- Did not result in better performing model on test data as well as Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70623875-b36e-4b0a-a8cb-d18ed062e340",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Results Table\n",
    "Data Versions\n",
    "- v1: Final Initial Allocation Ratio and Award/Usage Date Differences columns\n",
    "- v2: Create categorical features from dates, ensure all categorical features will be interpreted as such\n",
    "- v3: Add previous grant counts for organizations and piids. Filter out \"extreme\" data prior to 2012\n",
    "Tuning Versions\n",
    "- v1: Use score on hold out data to choose parameter value\n",
    "- v2: Use Grid Search CV to choose parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55516f14-88a7-40f9-a346-902e51c5ade1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=9079a0fa-1fea-4572-b551-89315c6546ec style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('9079a0fa-1fea-4572-b551-89315c6546ec').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data Version</th>\n",
       "      <th>Tuning Version</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Default</td>\n",
       "      <td>0.38772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBM</td>\n",
       "      <td>v1</td>\n",
       "      <td>v1</td>\n",
       "      <td>min_sample_leaf=20</td>\n",
       "      <td>0.38524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBM</td>\n",
       "      <td>v2</td>\n",
       "      <td>v1</td>\n",
       "      <td>min_sample_leaf=20</td>\n",
       "      <td>0.38807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>v3</td>\n",
       "      <td>v1</td>\n",
       "      <td>n_estimators=15</td>\n",
       "      <td>0.39912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBM</td>\n",
       "      <td>v3</td>\n",
       "      <td>v1</td>\n",
       "      <td>min_sample_leaf=20</td>\n",
       "      <td>0.38398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBM</td>\n",
       "      <td>v3</td>\n",
       "      <td>v2</td>\n",
       "      <td>min_sample_leaf=30</td>\n",
       "      <td>0.38699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     Model Data Version Tuning Version          Parameters      MSE\n",
       "0      EBM          NaN            NaN             Default  0.38772\n",
       "1      EBM           v1             v1  min_sample_leaf=20  0.38524\n",
       "2      EBM           v2             v1  min_sample_leaf=20  0.38807\n",
       "3  XGBoost           v3             v1     n_estimators=15  0.39912\n",
       "4      EBM           v3             v1  min_sample_leaf=20  0.38398\n",
       "5      EBM           v3             v2  min_sample_leaf=30  0.38699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('results_table.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fdf681-6d10-4bac-beaf-b665abfa0036",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Findings & Summary\n",
    "- EBM with min_samples_leaf=20 performed best\n",
    "- Significant data engineering only provided small improvement\n",
    "- [Notebook with model explanations](model_explanations.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
